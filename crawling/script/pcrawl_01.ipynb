{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# python crawling\n",
    "## request: html text load\n",
    "## BeautifulSoup: html text 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "<meta charset=\"utf-8\"/>\n",
       "<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n",
       "<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n",
       "<title>Web Crawling Example</title>\n",
       "</head>\n",
       "<body>\n",
       "<div>\n",
       "<p>a</p><p>b</p><p>c</p>\n",
       "</div>\n",
       "<div class=\"ex_class sample\">\n",
       "<p>X</p><p>Y</p><p>Z</p>\n",
       "</div>\n",
       "<div id=\"ex_id\">\n",
       "<p>1</p><p>2</p><p>3</p>\n",
       "</div>\n",
       "<h1>This is a heading.</h1>\n",
       "<p>This is a paragraph.</p>\n",
       "<p>This is another paragraph.</p>\n",
       "<a class=\"a sample\" href=\"www.naver.com\">네이버</a>\n",
       "<table border=\"1\">\n",
       "<tr>\n",
       "<td>A</td>\n",
       "<td>B</td>\n",
       "<td>C</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>x</td>\n",
       "<td>y</td>\n",
       "<td>z</td>\n",
       "</tr>\n",
       "</table>\n",
       "<ul>\n",
       "<li>삼겹살</li>\n",
       "<li>치킨</li>\n",
       "<li>비빕밥</li>\n",
       "</ul>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../data/00.Example.html\",encoding='utf8') as fp:\n",
    "    soup = BeautifulSoup(fp, 'html.parser')\n",
    "\n",
    "soup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. find(), find_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div>\n",
      "<p>a</p><p>b</p><p>c</p>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 div 태그의 내용을 가져오기\n",
    "first_div = soup.find('div')\n",
    "print(first_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p>a</p>, <p>b</p>, <p>c</p>]\n",
      "<p>b</p>\n"
     ]
    }
   ],
   "source": [
    "# 그중 p태그 리스트\n",
    "ps = first_div.find_all(\"p\")\n",
    "print(ps)\n",
    "print(ps[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. CSS selector: select_one, select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"ex_class sample\">\n",
       "<p>X</p><p>Y</p><p>Z</p>\n",
       "</div>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class 명이 ex_class인 태그 정보 가져오기\n",
    "div2 = soup.select_one('.ex_class')\n",
    "div2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"ex_class sample\">\n",
       "<p>X</p><p>Y</p><p>Z</p>\n",
       "</div>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 여러개의 클래스 이름을 가져올때\n",
    "div2 = soup.select_one('.ex_class.sample')\n",
    "div2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"ex_class sample\">\n",
       " <p>X</p><p>Y</p><p>Z</p>\n",
       " </div>,\n",
       " <a class=\"a sample\" href=\"www.naver.com\">네이버</a>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample을 포함한 모든 클래스 추출\n",
    "div3 = soup.select('.sample')\n",
    "div3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div id=\"ex_id\">\n",
       "<p>1</p><p>2</p><p>3</p>\n",
       "</div>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# id\n",
    "div4 = soup.select_one(\"#ex_id\")\n",
    "div4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<div>\n",
      "<p>a</p><p>b</p><p>c</p>\n",
      "</div>, <div class=\"ex_class sample\">\n",
      "<p>X</p><p>Y</p><p>Z</p>\n",
      "</div>, <div id=\"ex_id\">\n",
      "<p>1</p><p>2</p><p>3</p>\n",
      "</div>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# div 태그 전부\n",
    "div = soup.select('div')\n",
    "print(div)\n",
    "len(div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p>a</p>, <p>b</p>, <p>c</p>, <p>X</p>, <p>Y</p>, <p>Z</p>, <p>1</p>, <p>2</p>, <p>3</p>, <p>This is a paragraph.</p>, <p>This is another paragraph.</p>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p 태그 전부\n",
    "p_all = soup.select('p')\n",
    "print(p_all)\n",
    "len(p_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"a sample\" href=\"www.naver.com\">네이버</a>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a태그에서 class 이름이 a data 추출\n",
    "soup.select_one('a.a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div id=\"ex_id\">\n",
       "<p>1</p><p>2</p><p>3</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 태그가 div 이고 id가 ex_id인 정보 가져오기\n",
    "soup.select_one('div#ex_id')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a heading.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 태그 안의 정보\n",
    "soup.find('h1').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a heading.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h1').string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'www.naver.com'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 네이버\n",
    "soup.select_one('a.a').get_text()\n",
    "# 네이버 주소\n",
    "soup.select_one('a.a')['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삼겹살\n",
      "치킨\n",
      "비빕밥\n"
     ]
    }
   ],
   "source": [
    "# 삽겹살, 치킨, 비빔밥 출력\n",
    "x = soup.find_all('li')\n",
    "x\n",
    "for li in x:\n",
    "    print(li.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['삼겹살', '치킨', '비빕밥']\n"
     ]
    }
   ],
   "source": [
    "menu = []\n",
    "for li in x:\n",
    "    menu.append(li.get_text())\n",
    "print(menu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tr>\n",
      "<td>A</td>\n",
      "<td>B</td>\n",
      "<td>C</td>\n",
      "</tr>, <tr>\n",
      "<td>x</td>\n",
      "<td>y</td>\n",
      "<td>z</td>\n",
      "</tr>]\n",
      "ABC\n",
      "xyz\n"
     ]
    }
   ],
   "source": [
    "# table, abc, xyz\n",
    "trs = soup.find('table').find_all('tr')\n",
    "print(trs)\n",
    "for tr in trs:\n",
    "    tds = tr.find_all('td')\n",
    "    for td in tds:\n",
    "        print(td.get_text(), end='')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
